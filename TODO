TODO

Fix latitude and longitude saving for Sites and from Network to Site

Ensure classes are uniform

Create a test suite

Create search functions for each of the classes

Tidy the module - sort into sensible folders for further development

What kind of resolution will be needed for dateranges?

- Fix Segment and metadata files
- Tidy segment and meteadata files and fix imports to be in line with fn-local imports
- Metadata is currently being imported as meta, check naming

CRDS.py

 TODO - add control of daterange being written to file from
            data in Datasources



2019-05-15

segment.py

Column naming in gas tables?

JSON file for the processing and segmentation functions

Flag for upload of data -> segmentation functions

Interpretation layer

How to go from the selection of the file format to the processing function?

_datasource.py 

- Get the in-memory saving and storing of HDF files working


2019-05-16

Currently if a Datasource is create using from_data() it tries loading the data
from the object store - unsure if this is the best method

Could have a flag stating whether or not the object has been stored but this feels a bit crude


2019-05-17

Check the performance warning

/home/gar/Documents/Devel/hugs/modules/_datasource.py:167: PerformanceWarning: 
  your performance may suffer as PyTables will pickle object types that it cannot
  map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]
  
    out["data"] = self._data

Check the conversion of a Pandas Timestamp object to string and then to python datetime object 
by the Acquire functions


2019-05-20


2019-05-21 

Fix the naming of the Datasources in get_datasources()


2019-05-24

- Add pandas to NetCDF file conversion (in memory)
- Deletion of NaNs by row currently deletes all the data in that row regardless of other data 
possibly being in that row for another gas. When recombining with other dataframes we could just put in NaNs
where the data was previously deleted?



2019-05-29

Make CRDS to_string function more general and accept longer date strings

Improve search functionality for selection of available data
- Select per gas
- Show dateranges available for certain data?
- Order data within dataframe

Create a lookup of sites by their short code for metadata

Index by datetime ?

Filter down Metadata to Datasource


Remove column titles and make Data completely generic / universal

Metadata within the CRDS object leads to hierarchy - store metadata within the
objects themselves so they're not reliant on other objects

Object tags vs metadata in object store



2019-06-03

We're testing the integrity of the dataframe after reindexing in parse_gases, is this necessary?

See segment line 164


2019-06-04

Redo conversion to NetCDF test - error
Column names are different, check what it's testing for within the Pandas code

ValueError: cannot convert DataFrame with non-unique columns

2019-06-07

Update the way the start and end datetimes of data is recorded. Currently only the first dataframe is checked, as there will be many
need to improve this.

parse_gases now returns a tuple of a str and a list of tuples, this feels a bit over complicated, tidy it up if possible

get_datasources only takes data from a  single Datasource 

CRDS read_file also creates just a single Datasource

2019-06-10

Where to get Datasource IDs from?
How to add to parse_gases?

Currently just creating random UUIDs for each Datasource

CRDS creation - start and end time in the Metadata is different compared to that stored in the CRDS object.
The metadata has the data before the NaNs are removed.


CRDS, GC objects can become the first line for assessment of where the data being read in should go.

CRDS object -> Instruments -> Datasources

Todo for 2019-06-12

- Finish search functionality for gas searching
- Tests for Instrument
- Search for SettingWithCopy warning source
- GC file processing

Need to think about overlapping dateranges for searching the object store

Improve test for gas_search


2019-06-17

Add species specific dataset stuff to the CRDS class

See process_gcwerks CRDS fn



2019-06-26

On GC parse data why is data passed to the split frequency function None?
Check return values of functions handling the data


2019-07-02

1. Transfer any data held in Instrument to Datasource labels
2. Implement lookup tables for searching 
3. Functions ?

2019-07-04

Merge in sans instrument to search functions and get the search function working - Done

1. Go through issues and check Matt's comments - emailed Matt

2. Function for downloading of multiple sites data over a time period

3. How to store data for emission maps etc that are multi-dimensional and might not fit
in the tabular pandas format - HDF anyway?


2019-07-07

Searching and combining types of data correctly - recombination function should read the dict it's
passed with the data and recombine the dataframes based on the dict values

Fix the loading of CRDS and GC objects, there should only be one of both of these
Check on creation if the object already exists in the object store to prevent over-writing - Done


2019-07-09

Check dropping of NaNs in both GC and CRDS - ensure this is consistent

TODO - check source of test/modules/test_crds.py::test_read_folder
  /home/gar/Documents/Devel/hugs/test/modules/test_crds.py:54: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.
    CRDS.read_folder(folder_path=folder_path)

test/modules/test_crds.py::test_read_folder
  /home/gar/Documents/Devel/hugs/test/modules/test_crds.py:54: DtypeWarning: Columns (3,4,5,6,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.
    CRDS.read_folder(folder_path=folder_path)

-- Docs: https://docs.pytest.org/en/latest/warnings.html

Storing of Datasource by name has been disabled for now - seems unnecessary


2019-07-10

Tidy the search function for search_key and single_key - done

Add nbstripout to repo - done

2019-07-18

Cloud processing of GC and CRDS - return summary of processed data for confirmation
Cloud search functionality - search returns the data required in a NetCDF format? Maybe Pandas Dataframe for now
Search functionality should be accompanied by functions to recombine the get this data from the object store and recombine items
Create a Jupyter notebook interface, see voila for interfaces

Search and then download - user might want to redo search or modify it, saves downloading data multiple times



See Leaflet for map plotting, plotting layers on top of maps etc


2019-07-22

Clean up the testing get buckets, see Christophers 

@pytest.fixture(scope="session")
def bucket(tmpdir_factory):
    try:
        return get_service_account_bucket()
    except:
        d = tmpdir_factory.mktemp("objstore")
        push_is_running_service()
        bucket = get_service_account_bucket(str(d))
        while is_running_service():
            pop_is_running_service()
        return bucket

Sort out GC and CRDS creation problem

Added calls to the create function in load for both GC and CRDS, these should be removed
on first setup

Update Datasource list to set 