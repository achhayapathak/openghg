{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to upload, search and plot using the HUGS Cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, \"../../..\")\n",
    "sys.path.insert(0, \"../../../../acquire\")\n",
    "\n",
    "from HUGS.Processing import search\n",
    "from HUGS.Client import Process, Search, Retrieve\n",
    "\n",
    "from Acquire.ObjectStore import datetime_to_string\n",
    "from Acquire.Client import User, Drive, Service, PAR, Authorisation, StorageCreds\n",
    "\n",
    "from bqplot import pyplot as plt\n",
    "from bqplot import DateScale, LinearScale, LogScale, Axis, Lines, Figure, Scatter\n",
    "from random import randint    \n",
    "\n",
    "from numpy import random as np_random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import read_json as pd_read_json\n",
    "\n",
    "from ipywidgets import HBox, VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload modules before executing code, useful during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url= \"https://hugs.acquire-aaai.com/t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login by visiting: https://login.acquire-aaai.com?id=a0-a6/96.4e.55.8e\n",
      "(please check that this page displays the message 'big sheep stand happily')\n"
     ]
    }
   ],
   "source": [
    "# base_url = \"https://hugs.acquire-aaai.com/t\"\n",
    "\n",
    "user = User(username=\"gareth\", identity_url=F\"{base_url}/identity\")\n",
    "response = user.request_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we've logged in successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.wait_for_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to upload the data to the cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for test file paths\n",
    "def get_path(filename, data_type=\"CRDS\"):\n",
    "    dir_path = os.path.abspath(\"\")\n",
    "    test_data = f\"../../../test/data/proc_test_data/{data_type}\"\n",
    "    return os.path.join(dir_path, test_data, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a process object so we can send files to the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = Process(service_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time being clear Datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugs = Service(service_url=\"%s/hugs\" % base_url)\n",
    "# hugs.call_function(function=\"clear_datasources\", args={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error calling 'process' on 'https://hugs.acquire-aaai.com/t/hugs': unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-64bb220f6f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhfd_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hfd.picarro.1minute.100m_min.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CRDS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult_bsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbsd_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CRDS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bsd.picarro.1minute.248m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mresult_hfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhfd_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CRDS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hfd.picarro.1minute.100m_min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/hugs/HUGS/Client/_process.py\u001b[0m in \u001b[0;36mprocess_files\u001b[0;34m(self, user, files, data_type, source_name, overwrite, hugs_url, storage_url, datasource, site, instrument)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# file contains overlapping data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"process\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mdatasource_uuids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_service.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, function, args)\u001b[0m\n\u001b[1;32m    850\u001b[0m                               \u001b[0margs_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m                               \u001b[0mpublic_cert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_certificate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                               response_key=_get_private_key(\"function\"))\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_function.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(service_url, function, args, args_key, response_key, public_cert)\u001b[0m\n\u001b[1;32m    495\u001b[0m     return unpack_return_value(return_value=result, key=response_key,\n\u001b[1;32m    496\u001b[0m                                \u001b[0mpublic_cert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpublic_cert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                                function=function, service=service_url)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_function.py\u001b[0m in \u001b[0;36munpack_return_value\u001b[0;34m(return_value, key, public_cert, function, service)\u001b[0m\n\u001b[1;32m    349\u001b[0m     return unpack_arguments(return_value, key=key, public_cert=public_cert,\n\u001b[1;32m    350\u001b[0m                             \u001b[0mis_return_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                             service=service)\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_function.py\u001b[0m in \u001b[0;36munpack_arguments\u001b[0;34m(args, key, public_cert, is_return_value, function, service)\u001b[0m\n\u001b[1;32m    320\u001b[0m         return unpack_arguments(decrypted_data,\n\u001b[1;32m    321\u001b[0m                                 \u001b[0mis_return_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_return_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                                 function=function, service=service)\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpayload\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_function.py\u001b[0m in \u001b[0;36munpack_arguments\u001b[0;34m(args, key, public_cert, is_return_value, function, service)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"exception\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                     \u001b[0m_unpack_and_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0;32mfrom\u001b[0m \u001b[0mAcquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mService\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRemoteFunctionCallError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Devel/acquire/Acquire/Service/_function.py\u001b[0m in \u001b[0;36m_unpack_and_raise\u001b[0;34m(function, service, exdata)\u001b[0m\n\u001b[1;32m    401\u001b[0m             (function, service, _exception_to_string(e), exdata))\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/admin/handler.py\u001b[0m in \u001b[0;36m_base_handler\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/admin/handler.py\u001b[0m in \u001b[0;36m_handle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/admin/handler.py\u001b[0m in \u001b[0;36m_route_function\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mroute.py\u001b[0m in \u001b[0;36mhugs_functions\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/hugs_service/process.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/HUGS/Processing/_process.py\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/HUGS/Modules/_crds.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/function/python_modules/HUGS/Processing/_search.py\u001b[0m in \u001b[0;36mlookup_gas_datasources\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Error calling 'process' on 'https://hugs.acquire-aaai.com/t/hugs': unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "bsd_file = get_path(\"bsd.picarro.1minute.248m.dat\", data_type=\"CRDS\")\n",
    "hfd_file = get_path(\"hfd.picarro.1minute.100m_min.dat\", data_type=\"CRDS\")\n",
    "\"\"\n",
    "result_bsd = processing.process_files(user=user, files=bsd_file, data_type=\"CRDS\", source_name=\"bsd.picarro.1minute.248m\")\n",
    "result_hfd = processing.process_files(user=user, files=hfd_file, data_type=\"CRDS\", source_name=\"hfd.picarro.1minute.100m_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_bsd, \"\\n\\n\", result_hfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a search object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = Search(service_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(1970, 1,1)\n",
    "end = datetime.now()\n",
    "\n",
    "search_terms = [\"co\"]\n",
    "search_locations = []\n",
    "data_type = \"CRDS\"\n",
    "\n",
    "search_results = search.search(search_terms=search_terms, locations=search_locations, \n",
    "                               data_type=data_type, start_datetime=start, end_datetime=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bsd_co_248m': ['data/uuid/f23375aa-958c-4df2-899f-6e588601d3ab/2014-01-30T10:52:30_2014-01-30T14:20:30'],\n",
       " 'hfd_co_100m_min': ['data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2013-12-04T14:02:30_2013-12-25T22:56:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2014-01-01T18:25:30_2014-12-28T08:02:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2015-01-04T17:22:30_2015-12-30T14:55:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2016-01-06T18:01:30_2016-12-29T02:17:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2017-01-01T19:56:30_2017-12-26T07:35:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2018-01-02T13:10:30_2018-12-30T10:12:30',\n",
       "  'data/uuid/b815c0c2-ecf8-46fc-a19c-d06b261096c6/2019-01-06T11:02:30_2019-05-21T15:46:30']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the keys we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(search_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items stored at each key are the keys for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[\"bsd_co\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a list of the terms we want to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_download = [\"bsd_co\", \"hfd_co\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can (for now) pull this data from the object store for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve = Retrieve(service_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_keys = {key: search_results[key] for key in to_download}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrieve.retrieve(keys=download_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should make this a HUGS function within Client ?\n",
    "def json_to_dataframe(data_dict):\n",
    "    dataframes = {}\n",
    "    for key in data_dict:\n",
    "        dataframes[key] = pd_read_json(data_dict[key])\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "def download_keys(key_dict, download_keys=None):\n",
    "    \"\"\"\n",
    "        Downloads the keys and converts the passed JSON data into Pandas DataFrames\n",
    "        \n",
    "        Args:\n",
    "            key_dict (dict): Dictionary keyed by site_searchterm containing the\n",
    "                             keys to access the data\n",
    "            download_keys (list, default=None): List of keys to download\n",
    "        Returns:\n",
    "            dict: Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    if download_keys:\n",
    "        download_keys = {key: search_results[key] for key in to_download}\n",
    "    else:\n",
    "        download_keys = key_dict\n",
    "    \n",
    "    return json_to_dataframe(retrieve.retrieve(keys=download_keys))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from JSON to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = json_to_dataframe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some time series using bqplot. Here we use their internal object model. It's also possible to use a more `matplotlib` like interface. See https://bqplot.readthedocs.io/en/latest/usage.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = DateScale()\n",
    "y_scale = LinearScale()\n",
    "scales = {\"x\": x_scale, \"y\": y_scale}\n",
    "\n",
    "ax = Axis(label=\"Date\", scale=x_scale)\n",
    "ay = Axis(label=\"Count\", scale=y_scale, orientation=\"vertical\")\n",
    "\n",
    "bsd_data = dataframes[\"bsd_co\"]\n",
    "\n",
    "x_data = bsd_data.index\n",
    "y_data = bsd_data.iloc[:,0]\n",
    "\n",
    "scatter = Scatter(x=x_data, y=y_data, scales=scales)\n",
    "figure = Figure(marks=[scatter], axes=[ax, ay], animation_duration=1000)\n",
    "figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also just plot using `pandas` plotting inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd_data = dataframes[\"hfd_co\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd_data[\"co count\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple compounds for a single site - with the option to overlay "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from multiple sites as we have with our search call above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data from Bilsdale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsd_terms = [\"bsd_co\", \"bsd_co2\"]\n",
    "bsd_keys = {key: search_results[key] for key in bsd_terms}\n",
    "bsd_data = json_to_dataframe(retrieve.retrieve(keys=bsd_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot and compare the CO and CO2 data at Bilsdale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = DateScale()\n",
    "y_scale = LinearScale()\n",
    "scales = {\"x\": x_scale, \"y\": y_scale}\n",
    "\n",
    "ax = Axis(label=\"Date\", scale=x_scale)\n",
    "ay = Axis(label=\"Count\", scale=y_scale, orientation=\"vertical\")\n",
    "\n",
    "co_data = bsd_data[\"bsd_co\"]\n",
    "co2_data = bsd_data[\"bsd_co2\"]\n",
    "\n",
    "co_x_data = co_data.index\n",
    "co_y_data = co_data.iloc[:,0]\n",
    "\n",
    "co2_x_data = co2_data.index\n",
    "co2_y_data = co2_data.iloc[:,0]\n",
    "\n",
    "co_scatter = Scatter(x=co_x_data, y=co_y_data, scales=scales, colors=[\"LightGreen\"])\n",
    "co2_scatter = Scatter(x=co2_x_data, y=co2_y_data, scales=scales, colors=[\"steelblue\"])\n",
    "\n",
    "figure = Figure(marks=[co_scatter, co2_scatter], axes=[ax, ay], animation_duration=1000)\n",
    "figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot multiple compounds form different sites - with the option to overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsd_hfd_data = json_to_dataframe(retrieve.retrieve(keys=search_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsd_hfd_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload some data from Tacolneston, `tac.picarro.1minute.100m.min.dat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tac_file = get_path(\"tac.picarro.1minute.100m.min.dat\")\n",
    "result_tac = processing.process_files(user=user, files=tac_file, data_type=\"CRDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a new search for the TAC and HFD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(1970, 1,1)\n",
    "end = datetime.now()\n",
    "\n",
    "search_terms = [\"ch4\", \"co2\"]\n",
    "search_locations = [\"tac\", \"hfd\"]\n",
    "data_type = \"CRDS\"\n",
    "\n",
    "search_results = search.search(search_terms=search_terms, locations=search_locations, \n",
    "                               data_type=data_type, start_datetime=start, end_datetime=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd_tac_data = download_keys(key_dict=search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfd_tac_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4_scales = {\"x\": DateScale(), \"y\": LinearScale()}\n",
    "co2_scales = {\"x\": DateScale(), \"y\": LinearScale()}\n",
    "\n",
    "ax = Axis(label=\"Date\", scale=x_scale)\n",
    "ay = Axis(label=\"Count\", scale=y_scale, orientation=\"vertical\")\n",
    "\n",
    "tac_ch4_data = hfd_tac_data[\"tac_ch4\"]\n",
    "hfd_ch4_data = hfd_tac_data[\"hfd_ch4\"]\n",
    "\n",
    "tac_co2_data = hfd_tac_data[\"tac_co2\"]\n",
    "hfd_co2_data = hfd_tac_data[\"hfd_co2\"]\n",
    "\n",
    "tac_ch4_x = tac_ch4_data.index\n",
    "tac_ch4_y = tac_ch4_data[\"ch4 count\"]\n",
    "\n",
    "hfd_ch4_x = hfd_ch4_data.index\n",
    "hfd_ch4_y = hfd_ch4_data[\"ch4 count\"]\n",
    "\n",
    "tac_co2_x = tac_co2_data.index\n",
    "tac_co2_y = tac_co2_data[\"co2 count\"]\n",
    "\n",
    "hfd_co2_x = hfd_co2_data.index\n",
    "hfd_co2_y = hfd_co2_data[\"co2 count\"]\n",
    "\n",
    "# co_x_data = co_data.index\n",
    "# co_y_data = co_data.iloc[:,0]\n",
    "\n",
    "# co2_x_data = co2_data.index\n",
    "# co2_y_data = co2_data.iloc[:,0]\n",
    "\n",
    "tac_ch4_scatter = Lines(x=tac_ch4_x, y=tac_ch4_y, scales=ch4_scales, colors=[\"LightGreen\"])\n",
    "hfd_ch4_scatter = Lines(x=hfd_ch4_x, y=hfd_ch4_y, scales=ch4_scales, colors=[\"steelblue\"])\n",
    "\n",
    "tac_co2_scatter = Lines(x=tac_co2_x, y=tac_co2_y, scales=co2_scales, colors=[\"LightGreen\"])\n",
    "hfd_co2_scatter = Lines(x=hfd_co2_x, y=hfd_co2_y, scales=co2_scales, colors=[\"steelblue\"])\n",
    "\n",
    "ch4_figure = Figure(marks=[tac_ch4_scatter, hfd_ch4_scatter], axes=[ax, ay], animation_duration=1000, title=\"CH4\")\n",
    "co2_figure = Figure(marks=[tac_co2_scatter, hfd_co2_scatter], axes=[ax, ay], animation_duration=1000, title=\"CO2\")\n",
    "\n",
    "\n",
    "VBox(children=[ch4_figure, co2_figure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload some GC data and plot it\n",
    "### Here we'll upload from data from Capegrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cape_data = get_path(\"capegrim-medusa.18.C\", data_type=\"GC\")\n",
    "cape_prec = get_path(\"capegrim-medusa.18.precisions.C\", data_type=\"GC\")\n",
    "\n",
    "cape_tup = cape_data, cape_prec\n",
    "\n",
    "trinidad_data = get_path(\"trinidadhead.01.C\", data_type=\"GC\")\n",
    "trinidad_prec = get_path(\"trinidadhead.01.precisions.C\", data_type=\"GC\")\n",
    "\n",
    "trinidad_tup = trinidad_data, trinidad_prec\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cape = processing.process_files(user=user, files=cape_tup, data_type=\"GC\", source_name=\"capegrim-medusa.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_trinidad = processing.process_files(user=user, files=trinidad_tup, data_type=\"GC\", source_name=\"trinidadhead.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Capegrim file we should have 56 Datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result_cape[\"capegrim-medusa.18.C\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(1970, 1,1)\n",
    "end = datetime.now()\n",
    "\n",
    "search_terms = [\"H-2402\", \"CH3Cl\", \"CH2Cl2\", \"HFC-152a\"]\n",
    "search_locations = []\n",
    "data_type = \"GC\"\n",
    "\n",
    "search_results = search.search(search_terms=search_terms, locations=search_locations, \n",
    "                               data_type=data_type, start_datetime=start, end_datetime=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capegrim_data = download_keys(key_dict=search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capegrim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2402_data = capegrim_data[\"capegrim_H-2402\"][\"H-2402\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2402_data = capegrim_data[\"capegrim_H-2402\"][\"H-2402\"]\n",
    "CH3Cl_data = capegrim_data[\"capegrim_CH3Cl\"][\"CH3Cl\"]\n",
    "CH2Cl2_data = capegrim_data[\"capegrim_CH2Cl2\"][\"CH2Cl2\"]\n",
    "HFC152a_data = capegrim_data[\"capegrim_HFC-152a\"][\"HFC-152a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(tight_layout=True)\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "ax.plot(H2402_data.index, H2402_data.values)\n",
    "ax.set_xticks(ax.get_xticks()[::4])\n",
    "ax = fig.add_subplot(222)\n",
    "ax.plot(CH3Cl_data.index, CH3Cl_data.values)\n",
    "ax.set_xticks(ax.get_xticks()[::4])\n",
    "ax = fig.add_subplot(223)\n",
    "ax.plot(CH2Cl2_data.index, CH2Cl2_data.values)\n",
    "ax.set_xticks(ax.get_xticks()[::4])\n",
    "ax = fig.add_subplot(224)\n",
    "ax.plot(HFC152a_data.index, HFC152a_data.values)\n",
    "ax.set_xticks(ax.get_xticks()[::4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multiple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale = DateScale()\n",
    "y_scale = LinearScale()\n",
    "date_line_scales = {\"x\": x_scale, \"y\": y_scale}\n",
    "\n",
    "x_scale2 = DateScale()\n",
    "y_scale2 = LinearScale()\n",
    "date_line_scales2 = {\"x\": x_scale2, \"y\": y_scale2}\n",
    "\n",
    "ax = Axis(label=\"Date\", scale=x_scale, visible=True, tick_style={\"font-size\":12})\n",
    "ay = Axis(label=\"Count\", scale=y_scale, orientation=\"vertical\", visible=True, tick_style={\"font-size\":12})\n",
    "\n",
    "H2402_lines= Lines(x=H2402_data.index, y=H2402_data, scales=date_line_scales)\n",
    "H2402_fig = Figure(marks=[H2402_lines], axes=[ax,ay], title=\"H2402\")\n",
    "\n",
    "\n",
    "\n",
    "CH3Cl_lines= Lines(x=CH3Cl_data.index, y=CH3Cl_data, scales=date_line_scales2)\n",
    "CH3Cl_fig = Figure(marks=[CH3Cl_lines], axes=[ax,ay], title=\"CH3Cl\")\n",
    "\n",
    "# CH2Cl2_lines= Lines(x=CH2Cl2_data.index, y=CH2Cl2_data, scales={\"x\": DateScale(), \"y\": LinearScale()})\n",
    "# CH2Cl2_fig = Figure(marks=[CH2Cl2_lines], axes=[ax,ay], title=\"CH2Cl2\")\n",
    "\n",
    "# HFC152a_lines = Lines(x=HFC152a_data.index, y=HFC152a_data, scales={\"x\": DateScale(), \"y\": LinearScale()})\n",
    "# HFC152a_fig = Figure(marks=[HFC152a_lines], axes=[ax,ay], title=\"HFC152a\")\n",
    "\n",
    "# top_line = HBox(children=[H2402_fig, CH3Cl_fig])\n",
    "# bot_line = HBox(children=[CH2Cl2_fig, HFC152a_fig])\n",
    "\n",
    "# grid = VBox(children=[top_line, bot_line])\n",
    "# grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H2402_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH3Cl_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
