{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, \"../../..\")\n",
    "sys.path.insert(0, \"../../../../acquire\")\n",
    "\n",
    "from HUGS.Processing import search\n",
    "from HUGS.Client import Process, Search, Retrieve\n",
    "from Acquire.ObjectStore import datetime_to_string\n",
    "from Acquire.Client import User, Drive, Service, PAR, Authorisation, StorageCreds\n",
    "\n",
    "import ipyleaflet as ipl\n",
    "import ipywidgets as ipw\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Autoreload modules before executing code, useful during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for some EUROCOM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HUGS.Client import Search\n",
    "from HUGS.Util import get_datapath\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url= \"https://hugs.acquire-aaai.com/t\"\n",
    "search = Search(service_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acrg_json = get_datapath(filename=\"acrg_site_info.json\")\n",
    "with open(acrg_json, \"r\") as f:\n",
    "    acrg_sites = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel 1 - NOAA with EDGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.feature import BORDERS\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.cm as cm\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import ipyleaflet as ipl\n",
    "from random import uniform\n",
    "\n",
    "# filepath = \"/home/gar/Documents/Devel/hugs/user/notebooks/openghg/ch4-anthro_GLOBAL_2012.nc\"\n",
    "\n",
    "# Here try and work  out projection issues\n",
    "\n",
    "filepath = \"/home/home/gar/Documents/Devel/RSE/hugs/raw_data/ch4-anthro_GLOBAL_2012.nc\"\n",
    "\n",
    "ds = xr.open_dataset(filepath)\n",
    "\n",
    "domain = \"EUROPE\"\n",
    "\n",
    "fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection=ccrs.PlateCarree())\n",
    "ax = fig.add_subplot(111, projection=ccrs.Mercator())\n",
    "\n",
    "ax.coastlines(color=\"0.2\")\n",
    "ax.add_feature(BORDERS, edgecolor=\"0.5\")\n",
    "\n",
    "fp_name = \"flux\"\n",
    "lon_name = \"lon\"\n",
    "lat_name = \"lat\"\n",
    "\n",
    "cmap = cm.get_cmap(\"magma\")\n",
    "levels = np.linspace(np.percentile(ds[fp_name].values, 5), np.percentile(ds[fp_name].values, 95), 20)\n",
    "\n",
    "long_values = ds[fp_name][lon_name].values\n",
    "# long_values = long_values[:1800]\n",
    "lat_values = ds[fp_name][lat_name].values\n",
    "zero_values = ds[fp_name][:, :, 0].values\n",
    "\n",
    "# NE corner\n",
    "max_long = ds[fp_name][lon_name].max()\n",
    "max_lat = ds[fp_name][lat_name].max()\n",
    "\n",
    "# SW corner\n",
    "min_long = ds[fp_name][lon_name].min()\n",
    "min_lat =  ds[fp_name][lat_name].min()\n",
    "\n",
    "# print(ds.keys())\n",
    "\n",
    "# print(ds)\n",
    "\n",
    "\n",
    "# locations = [[uniform(-80, 80), uniform(-180, 180), uniform(0, 1000)] for i in range(1000)]\n",
    "\n",
    "# print(type(long_values))\n",
    "\n",
    "# print(len(long_values))\n",
    "# print(len(lat_values))\n",
    "# print(len(levels))\n",
    "\n",
    "# print(zero_values[15])\n",
    "\n",
    "\n",
    "# locations = [[a,b,uniform(0,100)] for a,b in zip(long_values, lat_values)]\n",
    "\n",
    "# for x in range(5):\n",
    "#     print(lat_values[x], long_values[x], zero_values[x])\n",
    "\n",
    "\n",
    "# locations = [long_values.tolist(), lat_values.tolist(), zero_values.tolist()]\n",
    "\n",
    "# print(locations[1])\n",
    "\n",
    "# m = ipl.Map(center=[0,0], zoom=2)\n",
    "# heat = ipl.Heatmap(locations=locations, radius=20)\n",
    "\n",
    "# m.add_layer(heat)\n",
    "\n",
    "# m\n",
    "\n",
    "#     plt.imshow(long_values, lat_values, zero_values)\n",
    "\n",
    "# ax.contourf(long_values, lat_values, zero_values,cmap=cm.get_cmap(\"magma\"), levels=levels)\n",
    "\n",
    "# fig.savefig(\"emissions_edgar.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_long, max_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_long, min_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_file = \"/home/gar/Documents/Devel/hugs/user/notebooks/openghg/ch4-anthro_GLOBAL_2012.nc\"\n",
    "\n",
    "plot_emissions(filepath=emissions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet as ipl\n",
    "    \n",
    "center = [38, 0]\n",
    "zoom = 0\n",
    "noaa_map = ipl.Map(center=center, zoom=zoom)\n",
    "\n",
    "# 179.95, dtype=float32), <xarray.DataArray 'lat' ()>\n",
    "#  array(89.95,\n",
    "\n",
    "edgar_image_path = \"emissions_edgar.png\"\n",
    "\n",
    "edgar_layer = ipl.ImageOverlay(url=edgar_image_path, bounds=((-80,-180),(90,180)))\n",
    "\n",
    "noaa_map.add_layer(edgar_layer)\n",
    "                               \n",
    "\n",
    "\n",
    "no_lat_long = []\n",
    "    \n",
    "for site in acrg_sites:\n",
    "    network_key = list(acrg_sites[site].keys())[0]\n",
    "    \n",
    "    if network_key == \"NOAA\":\n",
    "        site_data = acrg_sites[site][network_key]\n",
    "        \n",
    "        try:\n",
    "            lat = acrg_sites[site][network_key][\"latitude\"]\n",
    "            long = acrg_sites[site][network_key][\"longitude\"]\n",
    "\n",
    "            marker = ipl.Marker(location=(lat, long), draggable=False)\n",
    "            marker.popup = ipw.HTML(value=str(site))\n",
    "            noaa_map.add_layer(marker)\n",
    "        except:\n",
    "            no_lat_long.append(site)\n",
    "            \n",
    "        \n",
    "noaa_map\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel 2 - EUROCOM with footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icos_json = get_datapath(filename=\"icos_eurocom_sites.json\")\n",
    "\n",
    "center = [54.2361, -4.548]\n",
    "zoom = 3\n",
    "site_map = ipl.Map(center=center, zoom=zoom)\n",
    "\n",
    "with open(icos_json, \"r\") as f:\n",
    "    icos_sites = json.load(f)\n",
    "\n",
    "icos_markers = []\n",
    "\n",
    "for site in icos_sites:\n",
    "    lat = icos_sites[site][\"latitude\"]\n",
    "    long = icos_sites[site][\"longitude\"]\n",
    "    site_name = icos_sites[site][\"long_name\"]\n",
    "    \n",
    "    marker = ipl.Marker(location=(lat, long), draggable=False)\n",
    "    marker.popup = ipw.HTML(value=f\"Site code: {site}<br>Site name: {site_name}\")\n",
    "    site_map.add_layer(marker)\n",
    "\n",
    "site_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panel 3 - London with Canopy and Footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, basemaps, basemap_to_tiles\n",
    "\n",
    "\n",
    "center = [51.506815, -0.127710]\n",
    "zoom = 12\n",
    "map_london = ipl.Map(center=center, zoom=zoom)\n",
    "\n",
    "dark_matter_layer = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "map_london.add_layer(dark_matter_layer)\n",
    "\n",
    "lghg_sites = get_datapath(\"lghg_sites.json\")\n",
    "\n",
    "# Fix legend here\n",
    "marker_legend = ipw.HTML(value=\"<img src='marker-icon-green.png'>: Future<br>Blue marker: Current\")\n",
    "marker_control = ipl.WidgetControl(widget=marker_legend, position=\"topright\")\n",
    "\n",
    "map_london.add_control(marker_control)\n",
    "\n",
    "with open(lghg_sites, \"r\") as f:\n",
    "    lghg_data = json.load(f)\n",
    "    \n",
    "\n",
    "for site in lghg_data[\"current\"]:\n",
    "    curr_site = lghg_data[\"current\"][site]\n",
    "    \n",
    "    lat = curr_site[\"latitude\"]\n",
    "    long = curr_site[\"longitude\"]\n",
    "    site_name = curr_site[\"long_name\"]\n",
    "    \n",
    "    marker = ipl.Marker(location=(lat, long), draggable=False)\n",
    "    marker.popup = ipw.HTML(value=f\"Site code: {site}<br>Site name: {site_name}\")\n",
    "    map_london.add_layer(marker)\n",
    "    \n",
    "for site in lghg_data[\"future\"]:\n",
    "    fut_site = lghg_data[\"future\"][site]\n",
    "    \n",
    "    lat = fut_site[\"latitude\"]\n",
    "    long = fut_site[\"longitude\"]\n",
    "    site_name = fut_site[\"long_name\"]\n",
    "    \n",
    "    # Here we want a green icon\n",
    "    icon = ipl.Icon(icon_url='marker-icon-green.png', icon_size=[25, 40], icon_anchor=[12,15])\n",
    "    \n",
    "    marker = ipl.Marker(location=(lat, long), draggable=False, icon=icon)\n",
    "    marker.popup = ipw.HTML(value=f\"Site code: {site}<br>Site name: {site_name}\")\n",
    "    map_london.add_layer(marker)\n",
    "    \n",
    "    \n",
    "# Here we can load in just some canopy tiles for Central London\n",
    "# see https://data.london.gov.uk/dataset/curio-canopy and tile-grid-lookup.zip for the tiles\n",
    "\n",
    "# with open('/home/home/gar/Documents/Devel/RSE/hugs/canopy_data/gla-hexagon-grid-canopy-cover.geojson', 'r') as f:\n",
    "#   data = json.load(f)\n",
    "\n",
    "# geo_json = ipl.GeoJSON(data=data)\n",
    "# agage_map.add_layer(geo_json)\n",
    "\n",
    "agage = get_datapath(filename=\"icos_eurocom_sites.json\")\n",
    "\n",
    "map_london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
