{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenGHG for data providers: uploading and classifying data\n",
    "\n",
    "The OpenGHG platform has the ability to interpret and standardise data from multiple different sources. For measurement networks, this currently includes data from the following projects:\n",
    "\n",
    "- AGAGE\n",
    "- DECC\n",
    "- LondonGHG\n",
    "\n",
    "and can be expanded to include more as appropriate. At present, after being uploaded once this data will be available to access directly on the platform.\n",
    "\n",
    "The standardised format aims to be CF and CEDA compliant (as long as the necessary metadata is provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "old_store = os.environ[\"OPENGHG_PATH\"]\n",
    "os.environ[\"OPENGHG_PATH\"] = \"/home/gar/tmp_store\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual upload\n",
    "\n",
    "The current interface allows new measurement data to be uploaded directly to the platform by passing the data files along with a set of keywords so the data can be appropriately identified and categorised.\n",
    "\n",
    "For instance to upload a data file or files from the Billsdale site (site code \"BSD\") within the DECC network this could be uploaded and stored within the OpenGHG cloud store using the key words:\n",
    "\n",
    "- data_type of \"CRDS\"\n",
    "- site code of \"BSD\"\n",
    "- network of \"DECC\"\n",
    "\n",
    "The data_type here indicates the expected format of the data files themselves. This can be specific to the type of instrument being used, a site or a particular network (more details below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openghg.modules import ObsSurface\n",
    "from openghg.localclient import find_files\n",
    "from pathlib import Path\n",
    "\n",
    "folderpath = Path(\"/home/gar/Documents/Devel/RSE/openghg/data/demo/timeseries\")\n",
    "\n",
    "data_folders = {\n",
    "    \"CRDS\": folderpath.joinpath(\"CRDS\"),\n",
    "    \"GCWERKS\": {\"GCMD\": folderpath.joinpath(\"gc_gcmd\"), \"GCMS\": folderpath.joinpath(\"gc_gcms\")},\n",
    "}\n",
    "\n",
    "find_files(data_folders=data_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_type = \"CRDS\"\n",
    "site = \"bsd\"\n",
    "network = \"DECC\"\n",
    "\n",
    "decc_results = ObsSurface.read_file(decc_file, data_type, site, network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside:\n",
    "\n",
    "Accepted data types at the moment include:\n",
    "\n",
    "- CRDS (data from CRDS instruments, typically within the DECC and AGAGE networks)\n",
    "- GCWERKS (data from GC instruments, typically within the AGAGE network)\n",
    "- NOAA\n",
    "- THAMESBARRIER\n",
    "- BEACO2N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated upload\n",
    "\n",
    "For each site data providers will be given an API key. This will tie the data uploaded to a pre-defined set of metadata. There will be multiple ways of uploading data, either using the OpenGHG Python interface or more directly using `curl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ openghg upload <API_key> my_data.dat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking data\n",
    "\n",
    "When multiple sets of data are available for the same site and species, it is possible to set up a *ranking* to provide an order of preference for the data returned over a given time period. Once created, this ranking will then persist and will be used whenever this data is accessed.\n",
    "\n",
    "For example at the Billsdale site this has inlets at different heights. For different time periods, depending on the status of the instruments and the data availability, data at different data may be preferred. This can be indicated and then stored to influence which data source is returned for each species at Billsdale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COULD REMOVE THIS IF DATA IS ALREADY IN THE OBJECT STORE\n",
    "\n",
    "from openghg.util import bilsdale_datapaths\n",
    "from openghg.modules import ObsSurface\n",
    "\n",
    "# Load Billsdale data into object store\n",
    "bsd_paths = bilsdale_datapaths()\n",
    "uploaded = ObsSurface.read_file(filepath=bsd_paths, data_type=\"CRDS\", site=\"bsd\", network=\"DECC\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openghg.localclient import RankSources\n",
    "\n",
    "site = \"BSD\"  # Billsdale\n",
    "species = \"ch4\" # methane, \"ch4\"\n",
    "\n",
    "# Show all available sources which correspond to the same site and species\n",
    "r = RankSources()\n",
    "sources = r.get_sources(site=site, species=species)\n",
    "sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data uploaded for Billsdale, each source is stored with a key related to the species being measured, the inlet height and the instrument type:\n",
    " - ch4_248m_picarro\n",
    " - ch4_108m_picarro\n",
    " - ch4_42m_picarro\n",
    "\n",
    "So, for the methane data taken at the 108m inlet using the Picarro instrument the relevant key would be \"ch4_108m_picarro\".\n",
    "\n",
    "We can use this to check and set the rank for the data taken at the 108m inlet to be used preferentially when extracting the data in 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_specific_source(key=\"ch4_108m_picarro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.set_rank(key=\"ch4_108m_picarro\", rank=1, start_date=\"2015-01-01\", end_date=\"2016-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_specific_source(key=\"ch4_108m_picarro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also cover the rest of the date range for this data (01/01/2014 - 01/12/2021) by setting a ranking for the 248m inlet for the period before and after 2015 and check what values have been set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateranges_248m = [\"2014-01-01_2015-01-01\", \"2016-01-01_2020-12-01\"]\n",
    "r.set_rank(key=\"ch4_248m_picarro\", rank=1, dateranges=dateranges_248m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what values have been set for this site\n",
    "r.get_sources(site=\"bsd\", species=\"ch4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When retrieving the data from the object store, this now knows which data to extract for different time periods without needing to specify an inlet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2015, the data from 108m is returned\n",
    "\n",
    "from openghg.processing import get_obs_surface\n",
    "\n",
    "data = get_obs_surface(site=\"bsd\", species=\"ch4\", \n",
    "                       start_date=\"2015-01-01\", end_date=\"2015-02-01\")\n",
    "\n",
    "print(f\"Data from inlet at height: {data.metadata['inlet']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside 2015, the data from 248m is returned\n",
    "\n",
    "from openghg.processing import get_obs_surface\n",
    "\n",
    "data = get_obs_surface(site=\"bsd\", species=\"ch4\", \n",
    "                       start_date=\"2014-01-01\", end_date=\"2014-02-01\")\n",
    "\n",
    "print(f\"Data from inlet at height: {data.metadata['inlet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the ranking is not used, the data can still be accessed but the inlet height must be if there is any ambiguity for the data source being retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENGHG_PATH\"] = old_store"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be46fac04113c12cba86920494e488404427b4279e35c30cf0606e819f4acc5b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
